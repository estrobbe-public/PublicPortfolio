resource "google_compute_instance" "gke_cluster2_default_pool_8b8d378a_v4wd" {
  boot_disk {
    auto_delete = true
    device_name = "persistent-disk-0"

    initialize_params {
      image = "https://www.googleapis.com/compute/beta/projects/gke-node-images/global/images/gke-1335-gke1308000-cos-121-18867-199-88-c-pre"

      labels = {
        goog-fleet-project                    = "qwiklabs-gcp-01-2e74891f7230"
        goog-gke-cluster-id-base32            = "hgngvwj7gvdxzpsfyotcbsw3sdj4ebal4nuuyqvhyem6azz62ynq"
        goog-gke-node                         = ""
        goog-gke-node-pool-provisioning-model = "on-demand"
        goog-gke-volume                       = ""
        goog-k8s-cluster-location             = "us-west1-b"
        goog-k8s-cluster-name                 = "cluster2"
        goog-k8s-node-pool-name               = "default-pool"
      }

      size = 100
      type = "pd-balanced"
    }

    mode   = "READ_WRITE"
    source = "https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-2e74891f7230/zones/us-west1-b/disks/gke-cluster2-default-pool-8b8d378a-v4wd"
  }

  labels = {
    goog-fleet-project                    = "qwiklabs-gcp-01-2e74891f7230"
    goog-gke-cluster-id-base32            = "hgngvwj7gvdxzpsfyotcbsw3sdj4ebal4nuuyqvhyem6azz62ynq"
    goog-gke-cost-management              = ""
    goog-gke-node                         = ""
    goog-gke-node-pool-provisioning-model = "on-demand"
    goog-k8s-cluster-location             = "us-west1-b"
    goog-k8s-cluster-name                 = "cluster2"
    goog-k8s-node-pool-name               = "default-pool"
    managed-by-cnrm                       = "true"
  }

  machine_type = "e2-standard-4"

  metadata = {
    cluster-location           = "us-west1-b"
    cluster-name               = "cluster2"
    cluster-uid                = "399a6ad93f35477cbe45c3a620cadb90d3c2040be3694c42a7c119e0673ed61b"
    configure-sh               = "#!/usr/bin/env bash\n\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Due to the GCE custom metadata size limit, we split the entire script into two\n# files configure.sh and configure-helper.sh. The functionality of downloading\n# kubernetes configuration, manifests, docker images, and binary files are\n# put in configure.sh, which is uploaded via GCE custom metadata.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\n### Hardcoded constants\n\nDEFAULT_CNI_VERSION='v1.6.2-gke.8'\n# shellcheck disable=SC2034 # used by cni_hash_var which interpolates the platform\nDEFAULT_CNI_HASH_LINUX_AMD64='13a6522448cdf8df4689e73390aacd4a8dc49c069f1a6c18488b84520e6ab0cbdfda904b423d00a7c99e284d89748620fe11a6f9449633ffdf70b73c0e2902ae'\n# shellcheck disable=SC2034 # used by cni_hash_var which interpolates the platform\nDEFAULT_CNI_HASH_LINUX_ARM64='ce949a5493bd15e49edf1203edf4fdc8ea36a41c745b859a647b1dd0532a6ec5fa25d60656d5f2f8a5c048d568e390259acdef9db6b2bb96565d6233e72bc26f'\n\nDEFAULT_NPD_VERSION='v0.8.21-0-gca907dc1-gke.0'\nDEFAULT_NPD_HASH_AMD64='80bbccba6b4df7e62fc456814cc978e261f7e707fedd8cf525d8e30c6204bea317914d26fad0be5f0debe4b95934209ae927c55ed158ff4d9a6f4abff05fdcb9'\nDEFAULT_NPD_HASH_ARM64='bd0bd2c0f999ae05391efe8aea84bccd4ff8bc50d4c2334afc0d7fc531eb4814393c0cfaaad7f71e2964c280641eb3b957f916bb625addcb2eb43a7606fdf2d3'\n\nNPD_CUSTOM_PLUGINS_VERSION=\"v1.0.25\"\nNPD_CUSTOM_PLUGINS_TAR_AMD64_HASH=\"9b2602fe1e70eb7c9a8702cb38ec127254ce200096f72df4bb97a9ec76a1a6a5071faeff9b6c86332043eda870c69e6dab80d9f4c52079e2671a0592fe078d63\"\nNPD_CUSTOM_PLUGINS_TAR_ARM64_HASH=\"82af0c089dc20dbd88e6407459c5f2cbd633820447368092dc0b2d5a60392d7bfa6bfe4cfa21e8c18334433ab9ec596ebc6ced2f22c9ff1074b8d365dc22ff6a\"\n\nDEFAULT_CRICTL_VERSION='v1.31.1-gke.0'\nDEFAULT_CRICTL_AMD64_SHA512='7c0ea3355b53c79e00772cfdf0bf67d262a9a0e827fdcf5be956ff68be25b47d7cb5cd6b065e3de251efc7b4534961e37a37b9f0e3f1efa22dfe2b5149702889'\nDEFAULT_CRICTL_ARM64_SHA512='05c8a74117288def73c430aa7f207432c2b0e6f0560bb795f90debb65902a76e1d001e876a319cdf090c78ca4cbafa8021dd1a93e938aa74fd800677020446f6'\n\nDEFAULT_MOUNTER_ROOTFS_VERSION='v24.1.1'\nDEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512='722844337489d94afc1ae1cb1833bdefce16334fd9140646af2eb445f545e443dc53bec0b4935a0d2bb665971ac75313a7434750013361e989168cad1fe486fe'\nDEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512='3381e19f65b957d91410fe57df5c8fa45ee042fa6b47c4edefaf9ee512a154f1b707a4d77e5097a731472d0d12cb8684e62644b6db9fc2361800f1984fd31fab'\n\nRIPTIDE_FUSE_VERSION=\"v0.279.1\"\nRIPTIDE_FUSE_ARM64_SHA512='e08c56e47c7d7148518c0e6bc92a5ff4c0cf1ad2e8ec5a684775bb4bf1b4dacefdb64efba743bed960e016b64c190928bf0b157d72a1811cce9ed9daae736577'\nRIPTIDE_FUSE_BIN_ARM64_SHA512='54947bf9751babf86a130ee2c13dbcaca184c7e27b15525ebe601c9e3e7689270b45b01314828b472a392dc891bab74d3f0bf56a6cd230f414b24b6cd1207827'\nRIPTIDE_FUSE_AMD64_SHA512='3c7ddb3f4bac9212d9b457254d31b1a0de6d9ea7baec940fb4ab18f3b71c6d2b2d06c9517e8458ba088f5039de1148d1d92b92bfd104ece7d3f812ecdb1b0a4d'\nRIPTIDE_FUSE_BIN_AMD64_SHA512='5f4df931c4cbd827139c01476e3180cbf25e3d335a1181960a7b3cd9cb4e53535d5f9414660b7177e6fdef635354fdb64e5e5ff886123885bab7a5a30f5c1908'\n\nRIPTIDE_SNAPSHOTTER_VERSION=\"v1.33-7\"\nRIPTIDE_SNAPSHOTTER_SHA512='0807b358da0fc0ddbd6aba8966afb10885f58f12b6bcf59877aa1ba01068b016c3e0f441f2b903613699771aac5a669f18305cc8639a2e5f2548d4556ee64534'\nRIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512='6f2925ff35c4abafc70f6912fe23c718224fbdfa065d4432c328eca349372403b431be053e0108f8dcbb110261dbcd917a627e49f43843cf531a73da94c7ff61'\nRIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512='82198382f9a31b29106fa5454c6db64b838cd46ef0cac0819caec06d8ed178ea48437a66ad82c497c77b4e34a762a36de078bc3fe0d5c021d9b1fd8fce5e331b'\n\nAUTH_PROVIDER_GCP_VERSION=\"v0.1.0-gke.0\"\nAUTH_PROVIDER_GCP_HASH_LINUX_AMD64=\"e99c609f285cecd0f9473344de4b67dea3f311903bfa4158736cf63cab112ccc4f9829d5dfa030055899b22023369a17dd7a26c4d20601cfdd471a0a5c259867\"\nAUTH_PROVIDER_GCP_HASH_LINUX_ARM64=\"6444dd74815441517a403772ad734f9cfe6adfc9028ba0d50a93a7a0949676f3f8c424f89b0d0a8b344b4acebdce2f598884c2d41d694f895bd0bc6d30516f86\"\n\n# gke-exec-auth-plugin local version.\n# The URLs below are relative to ${STORAGE_ENDPOINT}/${EXEC_AUTH_PLUGIN_BUCKET}\nEXEC_AUTH_PLUGIN_BUCKET=\"gke-prod-binaries\"\nEXEC_AUTH_PLUGIN_VERSION=\"internal/gke-internal-branch-v1-33/f3f058859e54db63fd78adecd073be39db348785\"\nEXEC_AUTH_PLUGIN_LINUX_AMD64_HASH=\"1eacaa2fba8d9b993a1777b676aef18c4ab77a9965a2dab95d7e24115a4958161c1f23bd91a45bb6cb7157683ecd20ed4320b2b6eec2b922af59488b4738d037\"\nEXEC_AUTH_PLUGIN_LINUX_ARM64_HASH=\"1f14670fc37b5a9ab2c9fffd4e016649c1a9b457ad3270d43f736a0ea3247e265d9f49b09c2dfb42df9578e72ff2e5a248ce78f8be9d188e836ee922e7a52ae3\"\n\n###\n\n# Backend endpoints (configurable for TPC).\n# May be overridden when kube-env is sourced.\n#\n# NOTE: Endpoints should behave exactly like a GDU (Google Default Universe)\n# endpoint. E.g., An alternative `STORAGE_ENDPOINT` must have the same buckets\n# and paths as the `storage.googleapis.com` that this script depends on.\nSTORAGE_ENDPOINT=\"${STORAGE_ENDPOINT:-https://storage.googleapis.com}\"\nPGA_ENDPOINT=\"${PGA_ENDPOINT:-private.googleapis.com}\"\nKUBE_DOCKER_REGISTRY=\"${KUBE_DOCKER_REGISTRY:-gke.gcr.io}\"\n\n# Whether to configure private google access or not (defaults to true).\n# May be overridden when kube-env is sourced.\nCONFIGURE_PGA=\"${CONFIGURE_PGA:-true}\"\n\n# Standard curl flags.\nCURL_FLAGS=(\n  '--fail'\n  '--silent'\n  '--show-error'\n  '--retry' '5'\n  '--retry-delay' '3'\n  '--connect-timeout' '10'\n  '--retry-connrefused'\n)\n\n# This version needs to be the same as in gke/cluster/gce/gci/configure-helper.sh\nGKE_CONTAINERD_INFRA_CONTAINER=\"pause:3.8@sha256:880e63f94b145e46f1b1082bb71b85e21f16b99b180b9996407d61240ceb9830\"\n\n# Set max reboot retry 3 plus the inital boot count\nMAX_BOOT_COUNT=\"${MAX_BOOT_COUNT:-4}\"\n\nfunction set-broken-motd {\n  cat > /etc/motd <<EOF\nBroken (or in progress) Kubernetes node setup! Check the cluster initialization status\nusing the following commands.\n\nMaster instance:\n  - sudo systemctl status kube-master-installation\n  - sudo systemctl status kube-master-configuration\n\nNode instance:\n  - sudo systemctl status kube-node-installation\n  - sudo systemctl status kube-node-configuration\nEOF\n}\n\n# A function that fetches a GCE metadata value and echoes it out.\n# Args:\n#   $1 : URL path after /computeMetadata/v1/ (without heading slash).\n#   $2 : An optional default value to echo out if the fetch fails.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction get-metadata-value {\n  local default=\"${2:-}\"\n\n  local status\n  curl \"${CURL_FLAGS[@]}\" \\\n    -H 'Metadata-Flavor: Google' \\\n    \"http://metadata/computeMetadata/v1/${1}\" \\\n  || status=\"$?\"\n  status=\"${status:-0}\"\n\n  if [[ \"${status}\" -eq 0 || -z \"${default}\" ]]; then\n    return \"${status}\"\n  else\n    echo \"${default}\"\n  fi\n}\n\n# A function to fetch kube-env from GCE metadata server\n# or using hurl on the master if available\nfunction download-kube-env {\n  (\n    umask 077\n    local kube_env_path=\"/tmp/kube-env.yaml\"\n    if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n      local kube_env_path=\"${KUBE_HOME}/kube-env.yaml\"\n      download-kube-env-hurl \"${kube_env_path}\"\n    else\n      local meta_path=\"http://metadata.google.internal/computeMetadata/v1/instance/attributes/kube-env\"\n      echo \"Downloading kube-env via GCE metadata from ${meta_path} to ${kube_env_path}\"\n      retry-forever 10 curl \"${CURL_FLAGS[@]}\" \\\n        -H \"X-Google-Metadata-Request: True\" \\\n        -o \"${kube_env_path}\" \\\n        \"${meta_path}\"\n    fi\n\n    # Convert the yaml format file into a shell-style file.\n    eval \"$(python3 -c '''\nimport sys, yaml, shlex\nitems = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()\nfor k, v in items:\n  print(\"readonly {var}={value}\".format(var=k, value=shlex.quote(str(v))))\n''' < \"${kube_env_path}\" > \"${KUBE_HOME}/kube-env\")\"\n\n    # Leave kube-env if we are a master\n    if [[ \"${KUBERNETES_MASTER:-}\" != \"true\" ]]; then\n      rm -f \"${kube_env_path}\"\n    fi\n  )\n}\n\n# A function to pull kube-env from HMS using hurl\nfunction download-kube-env-hurl {\n  local -r kube_env_path=\"$1\"\n  local -r endpoint=$(get-metadata-value \"instance/attributes/gke-api-endpoint\")\n  local -r kube_env_hms_path=$(get-metadata-value \"instance/attributes/kube-env-path\")\n\n  echo \"Downloading kube-env via hurl from ${kube_env_hms_path} to ${kube_env_path}\"\n  retry-forever 30 \"${KUBE_HOME}/bin/hurl\" --hms_address \"$endpoint\" \\\n    --dst \"${kube_env_path}\" \\\n    \"${kube_env_hms_path}\"\n  chmod 600 \"${kube_env_path}\"\n}\n\nfunction download-kubelet-config {\n  local -r dest=\"$1\"\n  echo \"Downloading Kubelet config file, if it exists\"\n  # Fetch kubelet config file from GCE metadata server.\n  (\n    umask 077\n    local -r tmp_kubelet_config=\"/tmp/kubelet-config.yaml\"\n    retry-forever 10 curl \"${CURL_FLAGS[@]}\" \\\n      -H \"X-Google-Metadata-Request: True\" \\\n      -o \"${tmp_kubelet_config}\" \\\n      http://metadata.google.internal/computeMetadata/v1/instance/attributes/kubelet-config\n    # only write to the final location if curl succeeds\n    mv \"${tmp_kubelet_config}\" \"${dest}\"\n  )\n}\n\n# A function to pull kube-master-certs from HMS using hurl\nfunction download-kube-master-certs-hurl {\n  local -r endpoint=$(get-metadata-value \"instance/attributes/gke-api-endpoint\")\n  local -r tmp_kube_master_certs_path=\"/tmp/kube-master-certs.yaml\"\n  local -r kube_master_certs_path=\"${KUBE_HOME}/kube-master-certs\"\n  local -r kube_master_certs_hms_path=$(get-metadata-value \"instance/attributes/kube-master-certs-path\")\n\n  echo \"Downloading kube-master-certs via hurl from ${kube_master_certs_hms_path} to ${tmp_kube_master_certs_path}\"\n  retry-forever 30 \"${KUBE_HOME}\"/bin/hurl --hms_address \"$endpoint\" \\\n    --dst \"${tmp_kube_master_certs_path}\" \\\n    \"${kube_master_certs_hms_path}\"\n\n  # Convert the yaml format file into a shell-style file.\n  eval \"$(python3 -c '''\nimport shlex,sys,yaml\nitems = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()\nfor k, v in items:\n    print(\"readonly {var}={value}\".format(var=k, value=shlex.quote(str(v))))\n''' < \"${tmp_kube_master_certs_path}\" > \"${kube_master_certs_path}\")\"\n\n  # Remove the temp certs and strip perms for other users\n  rm -f \"${tmp_kube_master_certs_path}\"\n  chmod 600 \"${kube_master_certs_path}\"\n}\n\nfunction validate-hash {\n  local -r file=\"$1\"\n  local -r expected=\"$2\"\n\n  actual_sha1=$(sha1sum \"${file}\" | awk '{ print $1 }') || true\n  actual_sha512=$(sha512sum \"${file}\" | awk '{ print $1 }') || true\n  if [[ \"${actual_sha1}\" != \"${expected}\" ]] && [[ \"${actual_sha512}\" != \"${expected}\" ]]; then\n    echo \"== ${file} corrupted, sha1 ${actual_sha1}/sha512 ${actual_sha512} doesn't match expected ${expected} ==\"\n    return 1\n  fi\n}\n\n# Get default service account credentials of the VM.\nGCE_METADATA_INTERNAL=\"http://metadata.google.internal/computeMetadata/v1/instance\"\nfunction get-credentials {\n  curl \"${CURL_FLAGS[@]}\" \\\n    -H \"Metadata-Flavor: Google\" \\\n    \"${GCE_METADATA_INTERNAL}/service-accounts/default/token\" \\\n  | python3 -c 'import sys; import json; print(json.loads(sys.stdin.read())[\"access_token\"])'\n}\n\nfunction valid-storage-scope {\n  curl \"${CURL_FLAGS[@]}\" \\\n    -H \"Metadata-Flavor: Google\" \\\n    \"${GCE_METADATA_INTERNAL}/service-accounts/default/scopes\" \\\n  | grep -E \"auth/devstorage|auth/cloud-platform\"\n}\n\n# Retry a download until we get it. Takes a hash and a set of URLs.\n#\n# $1 is the sha512/sha1 hash of the URL. Can be \"\" if the sha512/sha1 hash is unknown.\n# $2+ are the URLs to download.\n# env var FORCE_USE_CREDENTIAL indicates whether to force using credential.\nfunction download-or-bust {\n  if [[ \"${ARTIFACT_DOWNLOAD_RESTRICTED:-}\" == \"true\" ]]; then\n    echo \"Cannot download: $* as downloading is restricted, exiting\"\n    exit 1\n  fi\n\n  local -r hash=\"$1\"\n  shift 1\n\n  while true; do\n    for url in \"$@\"; do\n      local file=\"${url##*/}\"\n      rm -f \"${file}\"\n      # if the url belongs to GCS API we should use oauth2_token in the headers if the VM service account has storage scopes\n      local curl_headers=\"\"\n\n      if [[ \"$url\" =~ ^${STORAGE_ENDPOINT}/.* ]] || [[ \"${FORCE_USE_CREDENTIAL:-false}\" == \"true\" ]] ; then\n        local canUseCredentials=0\n\n        echo \"Getting the scope of service account configured for VM.\"\n        if ! valid-storage-scope ; then\n          canUseCredentials=1\n          # this behavior is preserved for backward compatibility. We want to fail fast if SA is not available\n          # and try to download without SA if scope does not exist on SA\n          echo \"No service account or service account without storage scope. Attempt to download without service account token.\"\n        fi\n\n        if [[ \"${canUseCredentials}\" == \"0\" ]] ; then\n          echo \"Getting the service account access token configured for VM.\"\n          local access_token=\"\";\n          if access_token=$(get-credentials); then\n            echo \"Service account access token is received. Downloading ${url} using this token.\"\n          else\n            echo \"Cannot get a service account token. Exiting.\"\n            exit 1\n          fi\n\n          curl_headers=${access_token:+Authorization: Bearer \"${access_token}\"}\n        fi\n      fi\n      if ! curl ${curl_headers:+-H \"${curl_headers}\"} -f --ipv4 -Lo \"${file}\" --connect-timeout 20 --retry 6 --retry-delay 10 --retry-connrefused \"${url}\"; then\n        echo \"== Failed to download ${url}. Retrying. ==\"\n      elif [[ -n \"${hash}\" ]] && ! validate-hash \"${file}\" \"${hash}\"; then\n        echo \"== Hash validation of ${url} failed. Retrying. ==\"\n      else\n        if [[ -n \"${hash}\" ]]; then\n          echo \"== Downloaded ${url} (HASH = ${hash}) ==\"\n        else\n          echo \"== Downloaded ${url} ==\"\n        fi\n        return\n      fi\n    done\n  done\n}\n\nfunction record-preload-info {\n  echo \"$1,$2\" >> \"${KUBE_HOME}/preload_info\"\n  echo \"Recording preload info for ${1} ${2}\"\n}\n\nfunction is-preloaded {\n  local -r key=$1\n  local -r value=$2\n\n  if ! grep -qs \"${key},${value}\" \"${KUBE_HOME}/preload_info\"; then\n    if [[ \"${ARTIFACT_DOWNLOAD_RESTRICTED:-}\" == \"true\" ]]; then\n      echo \"No preload record found for ${key} and ${value} and downloading is restricted, exiting\"\n      exit 1\n    fi\n    if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n      echo \"No preload record found for ${key} and ${value}\"\n    fi\n    return 1\n  fi\n}\n\nfunction is-ubuntu {\n  [[ -f \"/etc/os-release\" && $(grep ^NAME= /etc/os-release) == 'NAME=\"Ubuntu\"' ]]\n}\n\nfunction split-commas {\n  echo -e \"${1//,/'\\n'}\"\n}\n\nfunction remount-flexvolume-directory {\n  local -r flexvolume_plugin_dir=$1\n  mkdir -p \"$flexvolume_plugin_dir\"\n  mount --bind \"$flexvolume_plugin_dir\" \"$flexvolume_plugin_dir\"\n  mount -o remount,exec \"$flexvolume_plugin_dir\"\n}\n\nfunction install-gci-mounter-tools {\n  CONTAINERIZED_MOUNTER_HOME=\"${KUBE_HOME}/containerized_mounter\"\n  if [[ -n \"${MOUNTER_ROOTFS_VERSION:-}\" ]]; then\n      local -r mounter_rootfs_version=\"${MOUNTER_ROOTFS_VERSION}\"\n      local -r mounter_rootfs_tar_sha=\"${MOUNTER_ROOTFS_TAR_SHA512}\"\n  else\n    local -r mounter_rootfs_version=\"${DEFAULT_MOUNTER_ROOTFS_VERSION}\"\n    case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n      linux/amd64)\n        local -r mounter_rootfs_tar_sha=\"${DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512}\"\n        ;;\n      linux/arm64)\n        local -r mounter_rootfs_tar_sha=\"${DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512}\"\n        ;;\n      *)\n        echo \"Unrecognized version and platform/arch combination:\"\n        echo \"$mounter_rootfs_version $HOST_PLATFORM/$HOST_ARCH\"\n        echo \"Set MOUNTER_ROOTFS_VERSION and MOUNTER_ROOTFS_TAR_SHA512 to overwrite\"\n        exit 1\n        ;;\n    esac\n  fi\n\n  if is-preloaded \"mounter\" \"${mounter_rootfs_tar_sha}\"; then\n    echo \"mounter is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading gci mounter tools.\"\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}\"\n  chmod a+x \"${CONTAINERIZED_MOUNTER_HOME}\"\n\n  # Copy the mounter binary downloaded with the k8s binaries tar file\n  cp \"${KUBE_HOME}/kubernetes/server/bin/mounter\" \"${CONTAINERIZED_MOUNTER_HOME}/mounter\"\n  chmod a+x \"${CONTAINERIZED_MOUNTER_HOME}/mounter\"\n  # Download the debian rootfs required for the mounter container\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}/rootfs\"\n  local -r mounter_rootfs_tar=\"containerized-mounter-${mounter_rootfs_version}_${HOST_PLATFORM}_${HOST_ARCH}.tar.gz\"\n  download-or-bust \"${mounter_rootfs_tar_sha}\" \"${STORAGE_ENDPOINT}/gke-release/containerized-mounter/${mounter_rootfs_version}/${mounter_rootfs_tar}\"\n  mv \"${KUBE_HOME}/${mounter_rootfs_tar}\" \"/tmp/${mounter_rootfs_tar}\"\n  tar xzf \"/tmp/${mounter_rootfs_tar}\" -C \"${CONTAINERIZED_MOUNTER_HOME}/rootfs\"\n  rm \"/tmp/${mounter_rootfs_tar}\"\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}/rootfs/var/lib/kubelet\"\n\n  record-preload-info \"mounter\" \"${mounter_rootfs_tar_sha}\"\n}\n\nfunction docker-installed {\n    if systemctl cat docker.service &> /dev/null ; then\n        return 0\n    else\n        return 1\n    fi\n}\n\nfunction disable_aufs() {\n  # disable aufs module if aufs is loaded\n  if lsmod | grep \"aufs\" &> /dev/null ; then\n    sudo modprobe -r aufs\n  fi\n}\n\nfunction detect_mtu {\n  local MTU=1460\n  if [[ \"${DETECT_MTU:-}\" == \"true\" ]];then\n    local default_nic\n    default_nic=$(ip route get 8.8.8.8 | sed -nr \"s/.*dev ([^\\ ]+).*/\\1/p\")\n    if [ -f \"/sys/class/net/$default_nic/mtu\" ]; then\n      MTU=$(cat \"/sys/class/net/$default_nic/mtu\")\n    fi\n  fi\n  echo \"$MTU\"\n}\n\n# This function cofigures docker. It has no conditional logic.\n# It will restart docker service so new settings will be picked up.\n# This method cannot be preloaded as the boot disk changes will not be persistet thru the reboots.\nfunction assemble-docker-flags {\n  # log the contents of the /etc/docker/daemon.json if already exists\n  if [ -f /etc/docker/daemon.json ]; then\n    echo \"Contents of the old docker config\"\n    cat /etc/docker/daemon.json\n  fi\n\n  disable_aufs\n\n  # COS and Ubuntu have different docker options configured as command line arguments.\n  # Use systemctl show docker to see the full list of options.\n  # When configuring Docker options you can use daemon.json or command line arguments\n  # The same option cannot be configured by both, even if it is a list option and can be repeated in the command line multiple times.\n  # This is why we are not simply configuring everything in daemon.json.\n\n  local MTU\n  MTU=\"$(detect_mtu)\"\n\n  # options to be set on COS, registry-mirror is pre-configured on COS\n  local os_specific_options=\"\\\"live-restore\\\": true,\\\n   \\\"storage-driver\\\": \\\"overlay2\\\",\\\n   \\\"mtu\\\": ${MTU},\"\n\n  if is-ubuntu; then\n    # Ubuntu already have everthing set\n    os_specific_options=\"\"\n  fi\n\n  # Important setting: set docker0 cidr to private ip address range to avoid conflict with cbr0 cidr range (\"bip\": \"169.254.123.1/24\")\n  cat > /etc/docker/daemon.json <<EOF\n{\n  \"pidfile\": \"/var/run/docker.pid\",\n  \"iptables\": false,\n  \"ip-masq\": false,\n  \"log-level\": \"warn\",\n  \"bip\": \"169.254.123.1/24\",\n  \"log-driver\": \"json-file\",\n  ${os_specific_options}\n  \"log-opts\": {\n      \"max-size\": \"10m\",\n      \"max-file\": \"5\"\n  }\n}\nEOF\n\n  # Do not move to the daemon.json file for backward compatibility.\n  # Command line and config file options cannot be both defined and custoemr customization may break.\n  # insecure-registry setting was inherited from the past, see b/203231428. Keeping for backward compatibility.\n  echo \"DOCKER_OPTS=\\\"--registry-mirror=https://mirror.gcr.io --insecure-registry 10.0.0.0/8\\\"\" > /etc/default/docker\n\n  echo \"Docker command line and configuration are updated. Restart docker to pick it up\"\n  systemctl restart docker\n}\n\n# Install node problem detector binary.\nfunction install-node-problem-detector {\n  if [[ -n \"${NODE_PROBLEM_DETECTOR_VERSION:-}\" ]]; then\n      local -r npd_version=\"${NODE_PROBLEM_DETECTOR_VERSION}\"\n      local -r npd_hash=\"${NODE_PROBLEM_DETECTOR_TAR_HASH}\"\n  else\n      local -r npd_version=\"${DEFAULT_NPD_VERSION}\"\n      case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n        linux/amd64)\n          local -r npd_hash=\"${DEFAULT_NPD_HASH_AMD64}\"\n          ;;\n        linux/arm64)\n          local -r npd_hash=\"${DEFAULT_NPD_HASH_ARM64}\"\n          ;;\n        # no other architectures are supported currently.\n        # Assumption is that this script only runs on linux,\n        # see cluster/gce/windows/k8s-node-setup.psm1 for windows\n        # https://github.com/kubernetes/node-problem-detector/releases/\n        *)\n          echo \"Unrecognized version and platform/arch combination:\"\n          echo \"$DEFAULT_NPD_VERSION $HOST_PLATFORM/$HOST_ARCH\"\n          echo \"Set NODE_PROBLEM_DETECTOR_VERSION and NODE_PROBLEM_DETECTOR_TAR_HASH to overwrite\"\n          exit 1\n          ;;\n      esac\n  fi\n  local -r npd_tar=\"node-problem-detector-${npd_version}-${HOST_PLATFORM}_${HOST_ARCH}.tar.gz\"\n\n  if is-preloaded \"${npd_tar}\" \"${npd_hash}\"; then\n    echo \"${npd_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading ${npd_tar}.\"\n  local -r npd_release_path=\"${NODE_PROBLEM_DETECTOR_RELEASE_PATH:-${STORAGE_ENDPOINT}/gke-release}\"\n  # We keep the tar file for LICENSES notices - do not remove it.\n  download-or-bust \"${npd_hash}\" \"${npd_release_path}/node-problem-detector/${npd_tar}\"\n  local -r npd_dir=\"${KUBE_HOME}/node-problem-detector\"\n  mkdir -p \"${npd_dir}\"\n  tar xzf \"${KUBE_HOME}/${npd_tar}\" -C \"${npd_dir}\" --overwrite\n  mv \"${npd_dir}/bin\"/* \"${KUBE_BIN}\"\n  chmod a+x \"${KUBE_BIN}/node-problem-detector\"\n  rmdir \"${npd_dir}/bin\"\n\n  record-preload-info \"${npd_tar}\" \"${npd_hash}\"\n}\n\n# Install node problem detector custom plugins.\nfunction install-npd-custom-plugins {\n  local -r version=\"${NPD_CUSTOM_PLUGINS_VERSION}\"\n  case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n    linux/amd64)\n      local -r hash=\"${NPD_CUSTOM_PLUGINS_TAR_AMD64_HASH}\"\n      ;;\n    linux/arm64)\n      local -r hash=\"${NPD_CUSTOM_PLUGINS_TAR_ARM64_HASH}\"\n      ;;\n    *)\n      echo \"Unrecognized version and platform/arch combination:\"\n      echo \"$NPD_CUSTOM_PLUGINS_VERSION $HOST_PLATFORM/$HOST_ARCH\"\n      exit 1\n  esac\n  local -r tar=\"npd-custom-plugins-${version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz\"\n\n  if is-preloaded \"${tar}\" \"${hash}\"; then\n    echo \"${tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading ${tar}.\"\n  download-or-bust \"${hash}\" \"${STORAGE_ENDPOINT}/gke-release/npd-custom-plugins/${version}/${tar}\"\n  local -r dir=\"${KUBE_HOME}/npd-custom-plugins\"\n  mkdir -p \"${dir}\"\n  tar xzf \"${KUBE_HOME}/${tar}\" -C \"${dir}\" --overwrite\n  local -r kube_bin_dir=\"${KUBE_HOME}/bin\"\n  cp -r \"${dir}/bins\"/* \"${kube_bin_dir}\"\n  rm -f \"${KUBE_HOME}/${tar}\"\n\n  record-preload-info \"${tar}\" \"${hash}\"\n}\n\nfunction install-cni-binaries {\n  local -r cni_version=${CNI_VERSION:-$DEFAULT_CNI_VERSION}\n  if [[ -n \"${CNI_VERSION:-}\" ]]; then\n    local -r cni_hash=\"${CNI_HASH:-}\"\n  else\n    local -r cni_hash_var=\"DEFAULT_CNI_HASH_${HOST_PLATFORM^^}_${HOST_ARCH^^}\"\n    local -r cni_hash=\"${!cni_hash_var}\"\n  fi\n\n  local -r cni_tar=\"cni-plugins-${HOST_PLATFORM}-${HOST_ARCH}-${cni_version}.tgz\"\n  local -r cni_url=\"${STORAGE_ENDPOINT}/gke-release/cni-plugins/${cni_version}/${cni_tar}\"\n\n  if is-preloaded \"${cni_tar}\" \"${cni_hash}\"; then\n    echo \"${cni_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading cni binaries\"\n  download-or-bust \"${cni_hash}\" \"${cni_url}\"\n  local -r cni_dir=\"${KUBE_HOME}/cni\"\n  mkdir -p \"${cni_dir}/bin\"\n  tar xzf \"${KUBE_HOME}/${cni_tar}\" -C \"${cni_dir}/bin\" --overwrite\n  mv \"${cni_dir}/bin\"/* \"${KUBE_BIN}\"\n  rmdir \"${cni_dir}/bin\"\n  rm -f \"${KUBE_HOME}/${cni_tar}\"\n\n  record-preload-info \"${cni_tar}\" \"${cni_hash}\"\n}\n\n# Install crictl binary.\n# Assumptions: HOST_PLATFORM and HOST_ARCH are specified by calling detect_host_info.\nfunction install-crictl {\n  if [[ -n \"${CRICTL_VERSION:-}\" ]]; then\n    local -r crictl_version=\"${CRICTL_VERSION}\"\n    local -r crictl_hash=\"${CRICTL_TAR_HASH}\"\n  else\n    local -r crictl_version=\"${DEFAULT_CRICTL_VERSION}\"\n    case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n      linux/amd64)\n        local -r crictl_hash=\"${DEFAULT_CRICTL_AMD64_SHA512}\"\n        ;;\n      linux/arm64)\n        local -r crictl_hash=\"${DEFAULT_CRICTL_ARM64_SHA512}\"\n        ;;\n      *)\n        echo \"Unrecognized version and platform/arch combination:\"\n        echo \"$DEFAULT_CRICTL_VERSION $HOST_PLATFORM/$HOST_ARCH\"\n        echo \"Set CRICTL_VERSION and CRICTL_TAR_HASH to overwrite\"\n        exit 1\n    esac\n  fi\n  local -r crictl=\"crictl-${crictl_version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz\"\n\n  # Create crictl config file.\n  cat > /etc/crictl.yaml <<EOF\nruntime-endpoint: ${CONTAINER_RUNTIME_ENDPOINT:-unix:///run/containerd/containerd.sock}\nEOF\n\n  if is-preloaded \"${crictl}\" \"${crictl_hash}\"; then\n    echo \"crictl is preloaded\"\n    return\n  fi\n\n  echo \"Downloading crictl\"\n  local -r crictl_path=\"${STORAGE_ENDPOINT}/gke-release/cri-tools/${crictl_version}\"\n  download-or-bust \"${crictl_hash}\" \"${crictl_path}/${crictl}\"\n  tar xf \"${crictl}\"\n  mv crictl \"${KUBE_BIN}/crictl\"\n  rm -f \"${crictl}\"\n\n  record-preload-info \"${crictl}\" \"${crictl_hash}\"\n}\n\nfunction preload-pause-image {\n  local -r pause_image=\"${KUBE_DOCKER_REGISTRY}/${GKE_CONTAINERD_INFRA_CONTAINER}\"\n  local pause_sha=\"${GKE_CONTAINERD_INFRA_CONTAINER#*@}\"\n  if [ -z \"$pause_sha\" ]; then\n    echo \"found no digest in GKE_CONTAINERD_INFRA_CONTAINER\"\n  else\n    for img in $(ctr -n=k8s.io images list -q | grep \"${pause_sha}\"); do\n      echo \"pause image ${img} of the same version is preloaded, retagging\"\n      if [[ \"${pause_image}\" != \"${img}\" ]]; then\n        ctr -n=k8s.io image tag --force \"${img}\" \"${pause_image}\"\n        pin-docker-image \"pause\"\n      fi\n      return\n    done\n  fi\n\n  # preloading pause image. It will be used in preloader and will be\n  # useful for staging builds where access_token is needed to pull the image\n  local access_token=\"\";\n\n  if access_token=$(get-credentials); then\n    ctr -n=k8s.io image pull --user=\"oauth2accesstoken:${access_token}\" \"${pause_image}\"\n  else\n    echo \"No access token. Pulling without it.\"\n    ctr -n=k8s.io image pull \"${pause_image}\"\n  fi\n  pin-docker-image \"pause\"\n}\n\nfunction install-exec-auth-plugin {\n  # We always use the URL/VERSION/HASH\n  # set at the top of this file,\n  # Values from kube-env are ignored in this version.\n  local -r plugin_base_url=\"${STORAGE_ENDPOINT}/${EXEC_AUTH_PLUGIN_BUCKET}/gke-exec-auth-plugin/${EXEC_AUTH_PLUGIN_VERSION}\"\n  case \"${HOST_PLATFORM}_${HOST_ARCH}\" in\n    linux_amd64)\n      local -r plugin_url=\"${plugin_base_url}/${HOST_PLATFORM}_${HOST_ARCH}/gke-exec-auth-plugin\"\n      local -r plugin_hash=\"${EXEC_AUTH_PLUGIN_LINUX_AMD64_HASH}\"\n      ;;\n\n    linux_arm64)\n      local -r plugin_url=\"${plugin_base_url}/${HOST_PLATFORM}_${HOST_ARCH}/gke-exec-auth-plugin\"\n      local -r plugin_hash=\"${EXEC_AUTH_PLUGIN_LINUX_ARM64_HASH}\"\n      ;;\n\n    *)\n      echo \"Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}\"\n      exit 1\n  esac\n\n  if is-preloaded \"gke-exec-auth-plugin\" \"${plugin_hash}\"; then\n    echo \"gke-exec-auth-plugin is preloaded\"\n    return\n  fi\n\n  echo \"Downloading gke-exec-auth-plugin binary\"\n  download-or-bust \"${plugin_hash}\" \"${plugin_url}\"\n  mv \"${KUBE_HOME}/gke-exec-auth-plugin\" \"${KUBE_BIN}/gke-exec-auth-plugin\"\n  chmod a+x \"${KUBE_BIN}/gke-exec-auth-plugin\"\n\n  local -r license_url=\"${plugin_base_url}/LICENSE\"\n  echo \"Downloading gke-exec-auth-plugin license\"\n  download-or-bust \"\" \"${license_url}\"\n  mv \"${KUBE_HOME}/LICENSE\" \"${KUBE_BIN}/gke-exec-auth-plugin-license\"\n\n  record-preload-info \"gke-exec-auth-plugin\" \"${plugin_hash}\"\n}\n\nfunction install-kube-manifests {\n  # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.\n  local dst_dir=\"${KUBE_HOME}/kube-manifests\"\n  mkdir -p \"${dst_dir}\"\n  local manifests_tar_urls\n  while IFS= read -r url; do\n    manifests_tar_urls+=(\"$url\")\n  done < <(split-commas \"${KUBE_MANIFESTS_TAR_URL}\")\n  local -r manifests_tar=\"${manifests_tar_urls[0]##*/}\"\n  if [ -n \"${KUBE_MANIFESTS_TAR_HASH:-}\" ]; then\n    local -r manifests_tar_hash=\"${KUBE_MANIFESTS_TAR_HASH}\"\n  else\n    echo \"Downloading k8s manifests hash (not found in env)\"\n    download-or-bust \"\" \"${manifests_tar_urls[@]/.tar.gz/.tar.gz.sha512}\"\n    local -r manifests_tar_hash=$(cat \"${manifests_tar}.sha512\")\n  fi\n\n  if is-preloaded \"${manifests_tar}\" \"${manifests_tar_hash}\"; then\n    echo \"${manifests_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading k8s manifests tar\"\n  download-or-bust \"${manifests_tar_hash}\" \"${manifests_tar_urls[@]}\"\n  tar xzf \"${KUBE_HOME}/${manifests_tar}\" -C \"${dst_dir}\" --overwrite\n  local -r kube_addon_registry=\"${KUBE_ADDON_REGISTRY:-k8s.gcr.io}\"\n  if [[ \"${kube_addon_registry}\" != \"k8s.gcr.io\" ]]; then\n    find \"${dst_dir}\" \\(-name '*.yaml' -or -name '*.yaml.in'\\) -print0 | \\\n      xargs -0 sed -ri \"s@(image:\\s.*)k8s.gcr.io@\\1${kube_addon_registry}@\"\n    find \"${dst_dir}\" \\(-name '*.manifest' -or -name '*.json'\\) -print0 | \\\n      xargs -0 sed -ri \"s@(image\\\":\\s+\\\")k8s.gcr.io@\\1${kube_addon_registry}@\"\n  fi\n  cp \"${dst_dir}/kubernetes/gci-trusty/gci-configure-helper.sh\" \"${KUBE_BIN}/configure-helper.sh\"\n  cp \"${dst_dir}/kubernetes/gci-trusty/configure-kubeapiserver.sh\" \"${KUBE_BIN}/configure-kubeapiserver.sh\"\n  if [[ -e \"${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh\" ]]; then\n    cp \"${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh\" \"${KUBE_BIN}/\"\n  fi\n  cp \"${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh\" \"${KUBE_BIN}/\"\n  cp \"${dst_dir}/kubernetes/gci-trusty/networkd-monitor.sh\" \"${KUBE_BIN}/networkd-monitor.sh\"\n\n  # Add the installable script to KUBE_BIN so installables can be processed.\n  cp \"${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/installable.py\" \"${KUBE_BIN}/installable.py\"\n\n\n  rm -f \"${KUBE_HOME}/${manifests_tar}\"\n  rm -f \"${KUBE_HOME}/${manifests_tar}.sha512\"\n\n  record-preload-info \"${manifests_tar}\" \"${manifests_tar_hash}\"\n}\n\n# Installs hurl to ${KUBE_HOME}/bin/hurl if not already installed.\nfunction install-hurl {\n  cd \"${KUBE_HOME}\"\n\n  local -r hurl_bin=\"hurl\"\n  local -r hurl_gcs_att=\"instance/attributes/hurl-gcs-url\"\n  local -r hurl_gcs_url=${HURL_GCS_URL:-$(get-metadata-value \"${hurl_gcs_att}\")}\n  local -r hurl_hash=${HURL_HASH:-$(get-metadata-value \"instance/attributes/hurl-bin-hash\")}\n\n  ### Fallback to old logic in case hurl_hash is not set\n  # extracting version from url, example:\n  # $ echo \"https://storage.googleapis.com/gke-master-startup/hurl/gke_master_hurl_20230824.00_p0/hurl\" | sed -n 's/.*gke_master_hurl_\\(.*\\)\\/hurl/\\1/p'\n  # 20230824.00_p0\n  local -r hurl_version=$(echo \"${hurl_gcs_url}\" | sed -n 's/.*gke_master_hurl_\\(.*\\)\\/hurl/\\1/p')\n\n  local -r hurl_preload_digest=${hurl_hash:-$hurl_version}\n\n  if is-preloaded \"${hurl_bin}\" \"${hurl_preload_digest}\"; then\n    echo \"install-hurl: hurl already installed\"\n    return\n  fi\n\n  if [[ -z \"${hurl_gcs_url}\" ]]; then\n    # URL not present in GCE Instance Metadata\n    echo \"install-hurl: Unable to find GCE metadata ${hurl_gcs_att}\"\n    return\n  fi\n\n  # Download hurl binary from a GCS bucket.\n  echo \"install-hurl: Installing hurl from ${hurl_gcs_url} ... \"\n  FORCE_USE_CREDENTIAL=true download-or-bust \"${hurl_hash}\" \"${hurl_gcs_url}\"\n  if [[ -f \"${KUBE_HOME}/${hurl_bin}\" ]]; then\n    chmod a+x \"${KUBE_HOME}/${hurl_bin}\"\n    mv \"${KUBE_HOME}/${hurl_bin}\" \"${KUBE_BIN}/${hurl_bin}\"\n    echo \"install-hurl: hurl installed to ${KUBE_BIN}/${hurl_bin}\"\n    record-preload-info \"${hurl_bin}\" \"${hurl_preload_digest}\"\n    return\n  fi\n}\n\nfunction install-k8s-pki {\n    local -r k8s_pki_url=\"${STORAGE_ENDPOINT}/${K8S_PKI_GCS_PATH}\"\n    # shellcheck disable=SC2153 # we use both capital and lowercase spelling intentionally\n    local -r k8s_pki_hash=\"${K8S_PKI_HASH}\"\n\n    if is-preloaded \"k8s_pki\" \"${k8s_pki_hash}\"; then\n      echo \"k8s_pki is preloaded\"\n      return\n    fi\n\n    echo \"Downloading k8s_pki binary\"\n    download-or-bust \"${k8s_pki_hash}\" \"${k8s_pki_url}\"\n    mv \"${KUBE_HOME}/k8s_pki\" \"${KUBE_BIN}/k8s_pki\"\n    chmod a+x \"${KUBE_BIN}/k8s_pki\"\n\n    echo \"Record k8s_pki preload info\"\n    record-preload-info \"k8s_pki\" \"${k8s_pki_hash}\"\n}\n\nfunction install-gcfsd {\n  echo \"Downloading Riptide FUSE client\"\n  if is-preloaded \"gcfsd\" \"${RIPTIDE_FUSE_VERSION}\"; then\n    echo \"gcfsd is preloaded.\"\n    return\n  fi\n\n  if [[ \"${HOST_ARCH}\" == \"arm64\" ]]; then\n    RIPTIDE_FUSE_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}/arm64\"\n    TAR_SHA=\"${RIPTIDE_FUSE_ARM64_SHA512}\"\n    BIN_SHA=\"${RIPTIDE_FUSE_BIN_ARM64_SHA512}\"\n  else\n    RIPTIDE_FUSE_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}\"\n    TAR_SHA=\"${RIPTIDE_FUSE_AMD64_SHA512}\"\n    BIN_SHA=\"${RIPTIDE_FUSE_BIN_AMD64_SHA512}\"\n  fi\n\n  # We keep the tar file for LICENSES notices\n  echo \"Downloading tarball for gcfsd\"\n  download-or-bust \"${TAR_SHA}\" \"${RIPTIDE_FUSE_STORE_PATH}/gcfsd.tar.gz\"\n\n  download-or-bust \"${BIN_SHA}\" \"${RIPTIDE_FUSE_STORE_PATH}/gcfsd\"\n  mv \"${KUBE_HOME}/gcfsd\" \"${KUBE_HOME}/bin/gcfsd\"\n  chmod a+x \"${KUBE_HOME}/bin/gcfsd\"\n  record-preload-info \"gcfsd\" \"${RIPTIDE_FUSE_VERSION}\"\n}\n\nfunction install-riptide-snapshotter {\n  echo \"Downloading Riptide snapshotter\"\n  if is-preloaded \"containerd-gcfs-grpc\" \"${RIPTIDE_SNAPSHOTTER_VERSION}\"; then\n    echo \"containerd-gcfs-grpc is preloaded.\"\n    return\n  fi\n  RIPTIDE_SNAPSHOTTER_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfs-snapshotter/${RIPTIDE_SNAPSHOTTER_VERSION}\"\n\n  # We keep the tar file for LICENSES notices\n  echo \"Downloading tarball for riptide-snapshotter\"\n  download-or-bust \"${RIPTIDE_SNAPSHOTTER_SHA512}\" \"${RIPTIDE_SNAPSHOTTER_STORE_PATH}/containerd-gcfs-grpc.tar.gz\"\n\n  if [[ \"${HOST_ARCH}\" == \"arm64\" ]]; then\n    RIPTIDE_SNAPSHOTTER_BINARY=\"containerd-gcfs-grpc-arm64\"\n    RIPTIDE_SNAPSHOTTER_BIN_SHA512=\"${RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512}\"\n  else\n    RIPTIDE_SNAPSHOTTER_BINARY=\"containerd-gcfs-grpc\"\n    RIPTIDE_SNAPSHOTTER_BIN_SHA512=\"${RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512}\"\n  fi\n\n  download-or-bust \"${RIPTIDE_SNAPSHOTTER_BIN_SHA512}\" \"${RIPTIDE_SNAPSHOTTER_STORE_PATH}/${RIPTIDE_SNAPSHOTTER_BINARY}\"\n  mv \"${KUBE_HOME}/${RIPTIDE_SNAPSHOTTER_BINARY}\" \"${KUBE_HOME}/bin/containerd-gcfs-grpc\"\n  chmod a+x \"${KUBE_HOME}/bin/containerd-gcfs-grpc\"\n  record-preload-info \"containerd-gcfs-grpc\" \"${RIPTIDE_SNAPSHOTTER_VERSION}\"\n}\n\n# Install Riptide FUSE client and Riptide snapshotter\nfunction install-riptide {\n  install-gcfsd\n  install-riptide-snapshotter\n}\n\n\nfunction source-gke-internal-configure-helper {\n  if [[ \"${GKE_INTERNAL_HELPER_SOURCED:-}\" != \"true\" ]]; then\n    source \"${KUBE_BIN}\"/gke-internal-configure-helper.sh\n  fi\n  GKE_INTERNAL_HELPER_SOURCED=\"true\"\n}\n\n\nfunction prepare-riptide-snapshotter-preloader {\n  source-gke-internal-configure-helper\n  log-wrap 'GKESetupContainerd' gke-setup-containerd\n}\n\nfunction process-installables-preloader {\n  source-gke-internal-configure-helper\n  log-wrap 'ProcessInstallablesPreloader' process-installables\n}\n\nfunction install-auth-provider-gcp {\n  case \"${HOST_ARCH}\" in\n    amd64)\n      local -r auth_provider_gcp_hash=\"${AUTH_PROVIDER_GCP_HASH_LINUX_AMD64}\"\n      ;;\n    arm64)\n      local -r auth_provider_gcp_hash=\"${AUTH_PROVIDER_GCP_HASH_LINUX_ARM64}\"\n      ;;\n    *)\n      echo \"Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}\"\n      exit 1\n  esac\n\n  if is-preloaded \"auth-provider-gcp\" \"${auth_provider_gcp_hash}\"; then\n    echo \"auth-provider-gcp is preloaded.\"\n    return\n  fi\n\n  local -r auth_provider_storage_url=\"${STORAGE_ENDPOINT}/gke-release/auth-provider-gcp/${AUTH_PROVIDER_GCP_VERSION}/${HOST_PLATFORM}_${HOST_ARCH}/auth-provider-gcp\"\n  echo \"Downloading auth-provider-gcp ${auth_provider_storage_url}\" .\n  download-or-bust \"${auth_provider_gcp_hash}\" \"${auth_provider_storage_url}\"\n\n  # Keep in sync with --image-credential-provider-bin-dir in cloud/kubernetes/distro/legacy/kube_env.go\n  mv \"${KUBE_HOME}/auth-provider-gcp\" \"${KUBE_BIN}\"\n  chmod a+x \"${KUBE_BIN}/auth-provider-gcp\"\n\n  record-preload-info \"auth-provider-gcp\" \"${auth_provider_gcp_hash}\"\n}\n\nfunction download-gvisor-installer {\n  local -r installer_image_hash=$1\n  local -r installer_image=\"${KUBE_DOCKER_REGISTRY}/gke-gvisor-installer@sha256:${installer_image_hash}\"\n  if access_token=$(get-credentials); then\n    \"${KUBE_BIN}/crictl\" pull --creds \"oauth2accesstoken:${access_token}\" \"${installer_image}\"\n  else\n    \"${KUBE_BIN}/crictl\" pull \"${installer_image}\"\n  fi\n}\n\nfunction configure-cgroup-mode {\n  if which cgroup_helper > /dev/null 2>&1; then\n    if [[ \"${CGROUP_MODE:-}\" == \"v1\" ]] && cgroup_helper show | grep -q 'unified'; then\n      cgroup_helper set hybrid\n      echo \"set cgroup config to hybrid, now rebooting...\"\n      reboot\n    elif [[ \"${CGROUP_MODE:-}\" == \"v2\" ]] && cgroup_helper show | grep -q 'hybrid'; then\n      cgroup_helper set unified\n      echo \"set cgroup config to unified, now rebooting...\"\n      reboot\n    fi\n  fi\n}\n\n# To improve the shieded VM reliability b/327650100\nfunction check-tpm-file {\n  if [[ -z \"${TPM_BOOTSTRAP_KEY:-}\" ]]; then\n    echo \"TPM_BOOTSTRAP_KEY is empty, thus vTPM is disabled, skip tpm file check\"\n    return 0\n  else\n    echo \"TPM_BOOTSTRAP_KEY is not empty, thus vTPM is enabled, checking tpm file\"\n    if [[ -e \"/dev/tpm0\" ]]; then\n      echo \"/dev/tpm0 exists.\"\n      return 0\n    else\n      echo \"/dev/tpm0 doesn't exist.\"\n      return 1\n    fi\n  fi\n}\n\nfunction detect-reboot-needed {\n  # Exit if it is on the master\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    return\n  fi\n\n  if [[ \"${ENABLE_BEST_EFFORT_NODE_REBOOT:-}\" == \"true\" ]]; then\n    if check-tpm-file; then\n      echo \"TPM is present; continuing bootstrap...\"\n      return\n    fi\n\n    echo \"TPM file check doesn't pass!\"\n    if ! REBOOT_HISTORY=$(journalctl --list-boots --quiet | wc -l); then\n      echo \"skip reboot attempt due to the journalctl error\"\n      return\n    fi\n    if [[ ${REBOOT_HISTORY} -gt ${MAX_BOOT_COUNT} ]]; then\n      echo \"best effort reboot attempt ${REBOOT_HISTORY} exceed ${MAX_BOOT_COUNT}! stop rebooting!\"\n    else\n      # write to a persistent file after reboot for NPD reporting event\n      # used in npd-custom-plugins/configs/node-reboot-monitor.json\n      mkdir -p /var/lib/gke\n      echo '1' >> /var/lib/gke/best_effort_reboot_marker\n      echo \"best effort reboot attempt ${REBOOT_HISTORY}! rebooting...\"\n      reboot\n    fi\n  fi\n}\n\n# A helper function for loading a docker image. It keeps trying up to 5 times.\n#\n# $1: Full path of the docker image\nfunction try-load-docker-image {\n  local -r img=$1\n  echo \"Try to load docker image file ${img}\"\n  # Temporarily turn off errexit, because we don't want to exit on first failure.\n  set +e\n  local -r max_attempts=5\n  local -i attempt_num=1\n\n  if [[ \"${CONTAINER_RUNTIME_NAME:-}\" == \"containerd\" || \"${CONTAINERD_TEST:-}\"  == \"containerd\" ]]; then\n    load_image_command=${LOAD_IMAGE_COMMAND:-ctr -n=k8s.io images import}\n  else\n    load_image_command=\"${LOAD_IMAGE_COMMAND:-}\"\n  fi\n\n  # Deliberately word split load_image_command\n  # shellcheck disable=SC2086\n  until timeout 300 ${load_image_command} \"${img}\"; do\n    if [[ \"${attempt_num}\" == \"${max_attempts}\" ]]; then\n      echo \"Fail to load docker image file ${img} using ${load_image_command} after ${max_attempts} retries. Exit!!\"\n      exit 1\n    else\n      attempt_num=$((attempt_num+1))\n      sleep 5\n    fi\n  done\n  # Re-enable errexit.\n  set -e\n}\n\n# Loads kube-system docker images. It is better to do it before starting kubelet,\n# as kubelet will restart docker daemon, which may interfere with loading images.\nfunction load-docker-images {\n  echo \"Start loading kube-system docker images\"\n  local -r img_dir=\"${KUBE_HOME}/kube-docker-files\"\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    try-load-docker-image \"${img_dir}/kube-apiserver.tar\"\n    try-load-docker-image \"${img_dir}/kube-controller-manager.tar\"\n    try-load-docker-image \"${img_dir}/kube-scheduler.tar\"\n  else\n    try-load-docker-image \"${img_dir}/kube-proxy.tar\"\n  fi\n}\n\n# A helper function for retagging a docker image with new tag and new registry.\n# $1: Image prefix\n# $2: Image tag\n# $3: Destination tag\n# $4: Destination registry\nfunction retag-docker-image {\n  local -r img_prefix=$1\n  local -r img_tag=$2\n  local -r dest_tag=$3\n  local -r dest_registry=$4\n  echo \"Retagging all images with prefix: ${img_prefix} and tag: ${img_tag} with new tag: ${dest_tag} and new registry: ${dest_registry}\"\n  local src_img=\"\"\n  for src_img in $(ctr -n=k8s.io images list -q | grep \"/${img_prefix}\" | grep \":${img_tag}$\"); do\n    dest_img=${src_img/:${img_tag}/:${dest_tag}}\n    dest_img=${dest_registry}/${dest_img##*/}\n    if [[ \"${dest_img}\" != \"${src_img}\" ]]; then\n      cmd=\"ctr -n=k8s.io image tag --force ${src_img} ${dest_img}\"\n      echo \"Retag command: ${cmd}\"\n      ${cmd}\n    fi\n  done\n}\n\n# Retags kube-system docker images with passed in kube-apiserver/kubelet versions.\nfunction retag-docker-images {\n  echo \"Start retagging kube-system docker images\"\n  local src_tag=\"\"\n  local dest_tag=\"\"\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    src_tag=$(cat /home/kubernetes/kube-docker-files/kube-apiserver.docker_tag)\n    # Keep the tag the same unless overridden\n    dest_tag=\"${src_tag}\"\n    if [[ -n \"${KUBE_APISERVER_VERSION:-}\" ]]; then\n      # Docker tags cannot contain '+', make CI versions a valid docker tag.\n      dest_tag=${KUBE_APISERVER_VERSION/+/_}\n    fi\n    retag-docker-image \"kube-apiserver\" \"${src_tag}\" \"${dest_tag}\" \"${KUBE_DOCKER_REGISTRY}\"\n    retag-docker-image \"kube-controller-manager\" \"${src_tag}\" \"${dest_tag}\" \"${KUBE_DOCKER_REGISTRY}\"\n    retag-docker-image \"kube-scheduler\" \"${src_tag}\" \"${dest_tag}\" \"${KUBE_DOCKER_REGISTRY}\"\n  else\n    src_tag=$(cat /home/kubernetes/kube-docker-files/kube-proxy.docker_tag)\n    # Keep the tag the same unless overridden\n    dest_tag=\"${src_tag}\"\n    if [[ -n \"${KUBELET_VERSION:-}\" ]]; then\n      # Docker tags cannot contain '+', make CI versions a valid docker tag.\n      dest_tag=${KUBELET_VERSION/+/_}\n    fi\n    retag-docker-image \"kube-proxy\" \"${src_tag}\" \"${dest_tag}\" \"${KUBE_DOCKER_REGISTRY}\"\n  fi\n}\n\nfunction ensure-container-runtime {\n  if [[ \"${CONTAINER_RUNTIME}\" == \"docker\" ]]; then\n    echo \"Dockershim is not supported. Container runtime must be set to containerd\"\n    exit 2\n  fi\n}\n\nfunction pin-docker-image {\n  local -r img_prefix=$1\n  echo \"Pinning: ${img_prefix}\"\n  for img in $(ctr -n=k8s.io images list -q | grep \"/${img_prefix}\"); do\n    cmd=\"ctr -n k8s.io images label ${img} io.cri-containerd.pinned=pinned\"\n    ${cmd}\n  done\n}\n\nfunction pin-docker-images {\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    pin-docker-image \"kube-apiserver\"\n    pin-docker-image \"kube-controller-manager\"\n    pin-docker-image \"kube-scheduler\"\n  else\n    pin-docker-image \"kube-proxy\"\n  fi\n}\n\n# Downloads kubernetes binaries and kube-system manifest tarball, unpacks them,\n# and places them into suitable directories. Files are placed in /home/kubernetes.\nfunction install-kube-binary-config {\n  cd \"${KUBE_HOME}\"\n  local server_binary_tar_urls\n  while IFS= read -r url; do\n    server_binary_tar_urls+=(\"$url\")\n  done < <(split-commas \"${SERVER_BINARY_TAR_URL}\")\n  local -r server_binary_tar=\"${server_binary_tar_urls[0]##*/}\"\n  if [[ -n \"${SERVER_BINARY_TAR_HASH:-}\" ]]; then\n    local -r server_binary_tar_hash=\"${SERVER_BINARY_TAR_HASH}\"\n  else\n    echo \"Downloading binary release sha512 (not found in env)\"\n    download-or-bust \"\" \"${server_binary_tar_urls[@]/.tar.gz/.tar.gz.sha512}\"\n    local -r server_binary_tar_hash=$(cat \"${server_binary_tar}.sha512\")\n  fi\n\n  if is-preloaded \"${server_binary_tar}\" \"${server_binary_tar_hash}\"; then\n    echo \"${server_binary_tar} is preloaded.\"\n  else\n    echo \"Downloading binary release tar\"\n    download-or-bust \"${server_binary_tar_hash}\" \"${server_binary_tar_urls[@]}\"\n    tar xzf \"${KUBE_HOME}/${server_binary_tar}\" -C \"${KUBE_HOME}\" --overwrite\n    # Copy docker_tag and image files to ${KUBE_HOME}/kube-docker-files.\n    local -r src_dir=\"${KUBE_HOME}/kubernetes/server/bin\"\n    local dst_dir=\"${KUBE_HOME}/kube-docker-files\"\n    mkdir -p \"${dst_dir}\"\n    cp \"${src_dir}/\"*.docker_tag \"${dst_dir}\"\n    if [[ \"${KUBERNETES_MASTER:-}\" == \"false\" ]]; then\n      cp \"${src_dir}/kube-proxy.tar\" \"${dst_dir}\"\n    else\n      cp \"${src_dir}/kube-apiserver.tar\" \"${dst_dir}\"\n      cp \"${src_dir}/kube-controller-manager.tar\" \"${dst_dir}\"\n      cp \"${src_dir}/kube-scheduler.tar\" \"${dst_dir}\"\n      cp -r \"${KUBE_HOME}/kubernetes/addons\" \"${dst_dir}\"\n    fi\n    load-docker-images\n    mv \"${src_dir}/kubelet\" \"${KUBE_BIN}\"\n    mv \"${src_dir}/kubectl\" \"${KUBE_BIN}\"\n\n    # Some older images have LICENSES baked-in as a file. Presumably they will\n    # have the directory baked-in eventually.\n    rm -rf \"${KUBE_HOME}\"/LICENSES\n    mv \"${KUBE_HOME}/kubernetes/LICENSES\" \"${KUBE_HOME}\"\n    mv \"${KUBE_HOME}/kubernetes/kubernetes-src.tar.gz\" \"${KUBE_HOME}\"\n\n    # Pin docker images to avoid GC\n    pin-docker-images\n\n    record-preload-info \"${server_binary_tar}\" \"${server_binary_tar_hash}\"\n  fi\n\n  retag-docker-images\n\n  if [[ \"${NETWORK_PROVIDER:-}\" == \"kubenet\" ]] || \\\n     [[ \"${NETWORK_PROVIDER:-}\" == \"cni\" ]]; then\n    install-cni-binaries\n  fi\n\n  # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.\n  install-kube-manifests\n  chmod -R 755 \"${KUBE_BIN}\"\n\n  # Install gci mounter related artifacts to allow mounting storage volumes in GCI\n  install-gci-mounter-tools\n\n  # Remount the Flexvolume directory with the \"exec\" option, if needed.\n  if [[ \"${REMOUNT_VOLUME_PLUGIN_DIR:-}\" == \"true\" && -n \"${VOLUME_PLUGIN_DIR:-}\" ]]; then\n    remount-flexvolume-directory \"${VOLUME_PLUGIN_DIR}\"\n  fi\n\n  # Install crictl on each node.\n  install-crictl\n\n  # Preload pause image\n  preload-pause-image\n\n  # Copy health check binaries to a tmpfs mount to reduce block IO usage.\n  setup-shm-healthcheck-binaries\n\n  # TODO(awly): include the binary and license in the OS image.\n  install-exec-auth-plugin\n\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"false\" ]]; then\n    install-node-problem-detector\n    install-npd-custom-plugins\n  fi\n\n  # Clean up.\n  rm -rf \"${KUBE_HOME}/kubernetes\"\n  rm -f \"${KUBE_HOME}/${server_binary_tar}\"\n  rm -f \"${KUBE_HOME}/${server_binary_tar}.sha512\"\n}\n\nfunction setup-shm-healthcheck-binaries() {\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    return\n  fi\n  if [[ \"${ENABLE_SHM_HEALTHCHECK_BINARIES:-}\" != \"true\" ]];then\n    return\n  fi\n\n  local -r shm_dir=\"${HEALTHCHECK_SHM_DIR:-/dev/kube_shm}\"\n  local -r shm_bin_dir=\"${shm_dir}/bin\"\n\n  mkdir -p \"$shm_dir\"\n  mount -t tmpfs -o exec none \"$shm_dir\"\n  mkdir \"${shm_bin_dir}\"\n\n  cp -f \"${KUBE_BIN}/crictl\" \"${shm_bin_dir}/crictl\"\n  cp -f \"$(which curl)\" \"${shm_bin_dir}/curl\"\n}\n\nfunction configure-pga-if-needed() {\n  echo \"Detecting connectivity to ${STORAGE_ENDPOINT}...\"\n  local status=0\n  curl --ipv4 -L --connect-timeout 10 --retry 3  --retry-connrefused \"${STORAGE_ENDPOINT}\" || status=\"$?\"\n  # connection is refused(7) or timeout(28).\n  if [[ \"${status}\" == \"7\" || \"${status}\" == \"28\" ]]; then\n    status=0\n    local pga_ip\n    pga_ip=$(curl \"${PGA_ENDPOINT}\" -w '%{remote_ip}' --connect-timeout 10 -s -o /dev/null) || status=\"$?\"\n    registry_domain=\"$(echo \"${KUBE_DOCKER_REGISTRY}\" | cut -d '/' -f 1)\"\n    if [[ \"${status}\" == \"0\" ]]; then\n      echo \"Configure /etc/hosts to use private google access\"\n      {\n        echo \"$pga_ip ${STORAGE_ENDPOINT#https://}\"\n        echo \"$pga_ip ${registry_domain}\"\n        # continue pga support for domain gke.gcr.io\n        echo \"$pga_ip gke.gcr.io\"\n      } >> /etc/hosts\n    fi\n  fi\n}\n\n# This function detects the platform/arch of the machine where the script runs,\n# and sets the HOST_PLATFORM and HOST_ARCH environment variables accordingly.\n# Callers can specify HOST_PLATFORM_OVERRIDE and HOST_ARCH_OVERRIDE to skip the detection.\n# This function is adapted from the detect_client_info function in cluster/get-kube-binaries.sh\n# and kube::util::host_os, kube::util::host_arch functions in hack/lib/util.sh\n# This function should be synced with detect_host_info in ./configure-helper.sh\nfunction detect_host_info() {\n  HOST_PLATFORM=${HOST_PLATFORM_OVERRIDE:-\"$(uname -s)\"}\n  case \"${HOST_PLATFORM}\" in\n    Linux|linux)\n      HOST_PLATFORM=\"linux\"\n      ;;\n    *)\n      echo \"Unknown, unsupported platform: ${HOST_PLATFORM}.\" >&2\n      echo \"Supported platform(s): linux.\" >&2\n      echo \"Bailing out.\" >&2\n      exit 2\n  esac\n\n  HOST_ARCH=${HOST_ARCH_OVERRIDE:-\"$(uname -m)\"}\n  case \"${HOST_ARCH}\" in\n    x86_64*|i?86_64*|amd64*)\n      HOST_ARCH=\"amd64\"\n      ;;\n    aHOST_arch64*|aarch64*|arm64*)\n      HOST_ARCH=\"arm64\"\n      ;;\n    *)\n      echo \"Unknown, unsupported architecture (${HOST_ARCH}).\" >&2\n      echo \"Supported architecture(s): amd64 and arm64.\" >&2\n      echo \"Bailing out.\" >&2\n      exit 2\n      ;;\n  esac\n}\n\n# Retries a command forever with a delay between retries.\n# Args:\n#  $1    : delay between retries, in seconds.\n#  $2... : the command to run.\nfunction retry-forever {\n  local -r delay=\"$1\"\n  shift 1\n\n  until \"$@\"; do\n    echo \"== $* failed, retrying after ${delay}s\"\n    sleep \"${delay}\"\n  done\n}\n\n# Initializes variables used by the log-* functions.\n#\n# get-metadata-value must be defined before calling this function.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-init {\n  # Used by log-* functions.\n  LOG_CLUSTER_ID=${LOG_CLUSTER_ID:-$(get-metadata-value 'instance/attributes/cluster-uid' 'get-metadata-value-error')}\n  LOG_INSTANCE_NAME=$(hostname || echo 'hostname-error')\n  LOG_BOOT_ID=$(journalctl --list-boots | grep -E '^ *0' | awk '{print $2}' || echo 'journalctl-error')\n  declare -Ag LOG_START_TIMES\n  declare -ag LOG_TRAP_STACK\n\n  LOG_STATUS_STARTED='STARTED'\n  LOG_STATUS_COMPLETED='COMPLETED'\n  LOG_STATUS_ERROR='ERROR'\n}\n\n# Sets an EXIT trap.\n# Args:\n#   $1:... : the trap command.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-trap-push {\n  local t=\"${*:1}\"\n  LOG_TRAP_STACK+=(\"${t}\")\n  # shellcheck disable=2064\n  trap \"${t}\" EXIT\n}\n\n# Removes and restores an EXIT trap.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-trap-pop {\n  # Remove current trap.\n  unset 'LOG_TRAP_STACK[-1]'\n\n  # Restore previous trap.\n  if [ ${#LOG_TRAP_STACK[@]} -ne 0 ]; then\n    local t=\"${LOG_TRAP_STACK[-1]}\"\n    # shellcheck disable=2064\n    trap \"${t}\" EXIT\n  else\n    # If no traps in stack, clear.\n    trap EXIT\n  fi\n}\n\n# Logs the end of a bootstrap step that errored.\n# Args:\n#  $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-error {\n  local bootstep=\"$1\"\n\n  log-proto \"${bootstep}\" \"${LOG_STATUS_ERROR}\" \"encountered non-zero exit code\"\n}\n\n# Wraps a command with bootstrap logging.\n# Args:\n#   $1    : bootstrap step name.\n#   $2... : the command to run.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-wrap {\n  local bootstep=\"$1\"\n  local command=\"${*:2}\"\n\n  log-trap-push \"log-error ${bootstep}\"\n  log-proto \"${bootstep}\" \"${LOG_STATUS_STARTED}\"\n  $command\n  log-proto \"${bootstep}\" \"${LOG_STATUS_COMPLETED}\"\n  log-trap-pop\n}\n\n# Logs a bootstrap step start. Prefer log-wrap.\n# Args:\n#   $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-start {\n  local bootstep=\"$1\"\n\n  log-trap-push \"log-error ${bootstep}\"\n  log-proto \"${bootstep}\" \"${LOG_STATUS_STARTED}\"\n}\n\n# Logs a bootstrap step end. Prefer log-wrap.\n# Args:\n#   $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-end {\n  local bootstep=\"$1\"\n\n  log-proto \"${bootstep}\" \"${LOG_STATUS_COMPLETED}\"\n  log-trap-pop\n}\n\n# Writes a log proto to stdout.\n# Args:\n#   $1: bootstrap step name.\n#   $2: status. Either 'STARTED', 'COMPLETED', or 'ERROR'.\n#   $3: optional status reason.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-proto {\n  local bootstep=\"$1\"\n  local status=\"$2\"\n  local status_reason=\"${3:-}\"\n\n  # Get current time.\n  local current_time\n  current_time=\"$(date --utc '+%s.%N')\"\n  # ...formatted as UTC RFC 3339.\n  local timestamp\n  timestamp=\"$(date --utc --date=\"@${current_time}\" '+%FT%T.%NZ')\"\n\n  # Calculate latency.\n  local latency='null'\n  if [ \"${status}\" == \"${LOG_STATUS_STARTED}\" ]; then\n    LOG_START_TIMES[\"${bootstep}\"]=\"${current_time}\"\n  else\n    local start_time=\"${LOG_START_TIMES[\"${bootstep}\"]}\"\n    unset 'LOG_START_TIMES['\"${bootstep}\"']'\n\n    # Bash cannot do non-integer math, shell out to awk.\n    latency=\"$(echo \"${current_time} ${start_time}\" | awk '{print $1 - $2}')s\"\n\n    # The default latency is null which cannot be wrapped as a string so we must\n    # do it here instead of the printf.\n    latency=\"\\\"${latency}\\\"\"\n  fi\n\n  printf '[cloud.kubernetes.monitoring.proto.SerialportLog] {\"cluster_hash\":\"%s\",\"vm_instance_name\":\"%s\",\"boot_id\":\"%s\",\"timestamp\":\"%s\",\"bootstrap_status\":{\"step_name\":\"%s\",\"status\":\"%s\",\"status_reason\":\"%s\",\"latency\":%s}}\\n' \\\n  \"${LOG_CLUSTER_ID}\" \"${LOG_INSTANCE_NAME}\" \"${LOG_BOOT_ID}\" \"${timestamp}\" \"${bootstep}\" \"${status}\" \"${status_reason}\" \"${latency}\"\n}\n\n# Prelaod components for both - preloader and runtime\n# Variables needed for this function to work will be set by the preloader\nfunction preload {\n  cd \"${KUBE_HOME}\"\n  if [[ \"${ENABLE_AUTH_PROVIDER_GCP:-\"\"}\" == \"true\" ]]; then\n    log-wrap 'InstallExternalCredentialProvider' install-auth-provider-gcp\n  fi\n\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    log-wrap 'InstallHurl' install-hurl\n  fi\n\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" && -n \"${K8S_PKI_GCS_PATH:-}\" ]]; then\n    log-wrap \"InstallK8sPki\" install-k8s-pki\n  fi\n\n  if [[ \"${KUBERNETES_MASTER:-}\" != \"true\" && -n \"${GVISOR_INSTALLER_IMAGE_HASH:-}\" ]]; then\n    log-wrap 'DownloadGvisorInstaller' download-gvisor-installer \"${GVISOR_INSTALLER_IMAGE_HASH}\"\n  fi\n}\n\n######### Main Function ##########\nlog-init\ndetect_host_info\n\n# Preloader will source this script, and skip the main function. The preloader\n# will choose what to preload by calling install-X functions directly.\n# When configure.sh is sourced by the preload script, $0 and $BASH_SOURCE are\n# different. $BASH_SOURCE still contains the path of configure.sh, while $0 is\n# the path of the preload script.\nif [[ \"$0\" != \"${BASH_SOURCE[0]}\" && \"${IS_PRELOADER:-\"false\"}\" == \"true\" ]]; then\n  # preload common components\n  preload\n  echo \"Running in preloader instead of VM bootsrapping. Skipping installation steps as preloader script will source configure.sh and call all non-common functions.\"\n  return\nfi\n\nlog-start 'ConfigureMain'\necho \"Start to install kubernetes files\"\n\n# if install fails, message-of-the-day (motd) will warn at login shell\nlog-wrap 'SetBrokenMotd' set-broken-motd\n\nKUBE_HOME=\"/home/kubernetes\"\nKUBE_BIN=\"${KUBE_HOME}/bin\"\n\nif [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n  if [[ \"${IS_PRELOADER:-}\" != \"true\" ]] &&\\\n     grep -qs \"PRELOADED,\" \"${KUBE_HOME}/preload_info\" &&\\\n     [[ $(get-metadata-value \"instance/attributes/fail-on-artifact-mismatch\" \"false\") == \"true\" ]]; then\n       # Disallow artifact downloads when:\n       # - running on master VMs\n       # - && not in preloader (running in bootstrap)\n       # - && VM image is preloaded\n       # - && failure on artifact mismatch feature is enabled\n       ARTIFACT_DOWNLOAD_RESTRICTED=\"true\"\n  fi\n\n  log-wrap 'InstallHurl' install-hurl\nfi\n\n# download and source kube-env\nlog-wrap 'DownloadKubeEnv' download-kube-env\nlog-wrap 'SourceKubeEnv' source \"${KUBE_HOME}/kube-env\"\n\nif [[ \"${CONFIGURE_PGA}\" == \"true\" ]]; then\n  configure-pga-if-needed\nfi\n\nlog-wrap 'ConfigureCgroupMode' configure-cgroup-mode\n\nlog-wrap 'BestEffortRebootDetection' detect-reboot-needed\n\nlog-wrap 'DownloadKubeletConfig' download-kubelet-config \"${KUBE_HOME}/kubelet-config.yaml\"\n\nif [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n  log-wrap 'DownloadKubeMasterCerts' download-kube-master-certs-hurl\nfi\n\nif docker-installed; then\n  # We still need to configure docker so it wouldn't reserver the 172.17.0/16 subnet\n  # And if somebody will start docker to build or pull something, logging will also be set up\n  log-wrap 'AssembleDockerFlags' assemble-docker-flags\nfi\n\n# preload common components\npreload\n\n# ensure chosen container runtime is present\nlog-wrap 'EnsureContainerRuntime' ensure-container-runtime\n\n# binaries and kube-system manifests\nlog-wrap 'InstallKubeBinaryConfig' install-kube-binary-config\n\n# install Riptide components\nif [[ \"${KUBERNETES_MASTER:-}\" != \"true\" ]]; then\n  log-wrap 'InstallRiptide' install-riptide\nfi\n\necho \"Done for installing kubernetes files\"\nlog-end 'ConfigureMain'\n"
    created-by                 = "projects/268855880648/zones/us-west1-b/instanceGroupManagers/gke-cluster2-default-pool-8b8d378a-grp"
    disable-legacy-endpoints   = "true"
    gci-metrics-enabled        = "true"
    gci-update-strategy        = "update_disabled"
    google-compute-enable-pcid = "true"
    instance-template          = "projects/268855880648/regions/us-west1/instanceTemplates/gke-cluster2-default-pool-8b8d378a"
    kube-env                   = "ALLOCATE_NODE_CIDRS: \"true\"\nAPI_SERVER_TEST_LOG_LEVEL: --v=3\nAUTOSCALER_ENV_VARS: kube_reserved=cpu=80m,memory=2623Mi,ephemeral-storage=41Gi;node_labels=cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=4,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=16,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true;arch=amd64;os=linux;os_distribution=cos;evictionHard=memory.available=100Mi,nodefs.available=10%,nodefs.inodesFree=5%,pid.available=10%\nCA_CERT: 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\nCLOUD_MONARCH_ENDPOINT: https://monitoring.googleapis.com/\nCLUSTER_IP_RANGE: 10.24.0.0/14\nCLUSTER_NAME: cluster2\nCONFIGURE_PGA: \"true\"\nCONTAINER_RUNTIME: containerd\nCONTAINER_RUNTIME_ENDPOINT: unix:///run/containerd/containerd.sock\nCONTAINER_RUNTIME_NAME: containerd\nCONTAINERD_DEPRECATION_CHECKER: \"true\"\nCONTAINERD_MAX_CONTAINER_LOG_LINE: \"262144\"\nCREATE_BOOTSTRAP_KUBECONFIG: \"false\"\nDETECT_LOCAL_MODE: NodeCIDR\nDETECT_MTU: \"true\"\nDNS_DOMAIN: cluster.local\nDNS_SERVER_IP: 34.118.224.10\nDOCKER_REGISTRY_MIRROR_URL: https://mirror.gcr.io\nELASTICSEARCH_LOGGING_REPLICAS: \"1\"\nENABLE_AUTH_PROVIDER_GCP: \"true\"\nENABLE_BEST_EFFORT_NODE_REBOOT: \"true\"\nENABLE_CLUSTER_DNS: \"true\"\nENABLE_CLUSTER_LOGGING: \"false\"\nENABLE_CLUSTER_MONITORING: none\nENABLE_CLUSTER_REGISTRY: \"false\"\nENABLE_CLUSTER_UI: \"true\"\nENABLE_CONNTRACK_EXEMPT_HC: \"true\"\nENABLE_CONTAINERD_METRICS: \"true\"\nENABLE_L7_LOADBALANCING: glbc\nENABLE_LATEST_NPD: \"true\"\nENABLE_METADATA_AGENT: \"\"\nENABLE_METADATA_CONCEALMENT: \"true\"\nENABLE_METRICS_SERVER: \"true\"\nENABLE_NETD: \"true\"\nENABLE_NODE_BFQ_IO_SCHEDULER: \"true\"\nENABLE_NODE_LOGGING: \"false\"\nENABLE_NODE_PROBLEM_DETECTOR: standalone\nENABLE_NODE_REGISTRATION_CHECKER: \"true\"\nENABLE_NODELOCAL_DNS: \"false\"\nENABLE_SHM_HEALTHCHECK_BINARIES: \"true\"\nENABLE_SYSCTL_TUNING: \"true\"\nENV_TIMESTAMP: \"2025-12-31T09:37:36+00:00\"\nEXTRA_DOCKER_OPTS: --insecure-registry 10.0.0.0/8\nEXTRA_POD_SYSCTLS: net.ipv6.conf.all.disable_ipv6=1,net.ipv6.conf.default.disable_ipv6=1\nFEATURE_GATES: RotateKubeletServerCertificate=true,ExecProbeTimeout=false\nFLUENTD_CONTAINER_RUNTIME_SERVICE: containerd\nGVISOR_HOST_SETTINGS: enforce\nGVISOR_METRIC_SERVER: 127.0.0.1:9115\nHEAPSTER_USE_NEW_STACKDRIVER_RESOURCES: \"true\"\nHEAPSTER_USE_OLD_STACKDRIVER_RESOURCES: \"false\"\nHPA_USE_REST_CLIENTS: \"true\"\nINSTANCE_PREFIX: gke-cluster2-399a6ad9\nKUBE_ADDON_REGISTRY: k8s.gcr.io\nKUBE_CLUSTER_DNS: 34.118.224.10\nKUBE_DOCKER_REGISTRY: us-west1-artifactregistry.gcr.io/gke-release/gke-release\nKUBE_MANIFESTS_TAR_HASH: 13b1d079f7333b5a77542c90ce5b98f4f7ad52a4f40a4f0bc30af0492d131e7df877a71af3a1d99860f751f3324df1c3c2981186a969322c49b58aa9b037ca72\nKUBE_MANIFESTS_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.33.5-gke.1308000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.33.5-gke.1308000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.33.5-gke.1308000/kubernetes-manifests.tar.gz\nKUBE_PROXY_TOKEN: mSloCOAsIF-hfnO73BWecr1EyjcUU6RqAP2BFgzWQAc=\nKUBELET_ARGS: --v=2 --cloud-provider=external --experimental-mounter-path=/home/kubernetes/containerized_mounter/mounter\n  --cert-dir=/var/lib/kubelet/pki/ --kubeconfig=/var/lib/kubelet/kubeconfig --image-credential-provider-config=/etc/srv/kubernetes/cri_auth_config.yaml\n  --image-credential-provider-bin-dir=/home/kubernetes/bin --max-pods=110 --node-labels=cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=4,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=16,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true\n  --volume-plugin-dir=/home/kubernetes/flexvolume --node-status-max-images=25 --container-runtime-endpoint=unix:///run/containerd/containerd.sock\n  --runtime-cgroups=/system.slice/containerd.service --registry-qps=10 --registry-burst=20\nKUBELET_HTTP2_PING_TIMEOUT_SECONDS: \"5\"\nKUBELET_HTTP2_READ_IDLE_TIMEOUT_SECONDS: \"10\"\nKUBELET_VERSION: v1.33.5-gke.1308000\nKUBERNETES_MASTER: \"false\"\nKUBERNETES_MASTER_NAME: 10.138.0.4\nLOAD_IMAGE_COMMAND: ctr -n=k8s.io images import\nLOGGING_DESTINATION: \"\"\nLOGGING_STACKDRIVER_RESOURCE_TYPES: \"\"\nMONITORING_FLAG_SET: \"true\"\nNETWORK_PROVIDER: cni\nNODE_BFQ_IO_SCHEDULER_IO_WEIGHT: \"1200\"\nNODE_LOCAL_SSDS_EXT: \"\"\nNODE_PROBLEM_DETECTOR_ADC_CONFIG: \"\\n{\\n\\t\\\"type\\\": \\\"external_account\\\",\\n\\t\\\"subject_token_type\\\":\n  \\\"node_service_account_id_token\\\",\\n\\t\\\"audience\\\": \\\"https://container.googleapis.com/v1/projects/268855880648/locations/us-west1-b/clusters/cluster2/nodePools/default-pool/systemComponents/node-problem-detector/generateNodeServiceAccountToken\\\",\\n\\t\\\"token_url\\\":\n  \\\"https://container.googleapis.com/v1/projects/268855880648/locations/us-west1-b/clusters/cluster2/generateClusterNodeAgentToken\\\",\\n\\t\\\"project_id\\\":\n  \\\"qwiklabs-gcp-01-2e74891f7230\\\",\\n\\t\\\"credential_source\\\": {\\n\\t\\t\\\"url\\\": \\\"http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/identity?format=full&audience=https://container.googleapis.com/v1/projects/268855880648/locations/us-west1-b/clusters/cluster2/nodePools/default-pool/systemComponents/node-problem-detector/generateNodeServiceAccountToken\\\",\\n\\t\\t\\\"headers\\\":\n  {\\n\\t\\t\\t\\\"Metadata-Flavor\\\": \\\"Google\\\"\\n\\t\\t}\\n\\t}\\n}\"\nNODE_PROBLEM_DETECTOR_DPV2_MIGRATION_SUPPORTED_CNI_TYPES: bandwidth,bridge,gke,istio-cni,loopback,portmap,ptp\nNON_MASQUERADE_CIDR: 0.0.0.0/0\nREMOUNT_VOLUME_PLUGIN_DIR: \"true\"\nRENDERED_INSTALLABLES: '{\"advanceddatapath\":{\"cilium-cni\":{\"kind\":\"container\",\"apiVersion\":\"installable.gke.io/v1\",\"metadata\":{\"name\":\"cilium-cni\",\"creationTimestamp\":null},\"os\":\"linux\",\"arch\":\"MULTI\",\"version\":\"v1.16.10-gke1.33-gke.19\",\"remoteURL\":\"us-west1-artifactregistry.gcr.io/gke-release/gke-release/cilium/cilium:v1.16.10-gke1.33-gke.19\",\"digest\":\"3a47d7650146999813dd4f672638cefb7dc54b894982b4db161cb2a132053117\",\"digestAlgo\":\"sha256\",\"run\":{\"ctrArgs\":[\"--mount=type=bind,src=/home/kubernetes/bin,dst=/host/opt/cni/bin,options=rbind\",\"--env=CNI_DIR=/host/opt/cni\"],\"containerArgs\":[\"/install-plugin.sh\"]}}}}'\nREQUIRE_METADATA_KUBELET_CONFIG_FILE: \"true\"\nSALT_TAR_HASH: \"\"\nSALT_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.33.5-gke.1308000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.33.5-gke.1308000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.33.5-gke.1308000/kubernetes-salt.tar.gz\nSERVER_BINARY_TAR_HASH: 6f9a7c88cacf0ff3fee6f1d96506eaefb52c1cfc4b4d28772e734743ce0c2c934f0013053e84ec9e1e8f05137cc45a136fa1a3bffd72c6d6e2e0b85dd4eb2199\nSERVER_BINARY_TAR_URL: https://storage.googleapis.com/gke-release/kubernetes/release/v1.33.5-gke.1308000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.33.5-gke.1308000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.33.5-gke.1308000/kubernetes-server-linux-amd64.tar.gz\nSERVICE_CLUSTER_IP_RANGE: 34.118.224.0/20\nSTACKDRIVER_ENDPOINT: https://logging.googleapis.com\nSTORAGE_ENDPOINT: https://storage.googleapis.com\nSYSCTL_OVERRIDES: \"\"\nTPM_BOOTSTRAP_CERT: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQzakNDQWthZ0F3SUJBZ0lSQUtsd3Y4bkR6dUlFekNmWFZoMU8waGN3RFFZSktvWklodmNOQVFFTEJRQXcKTHpFdE1Dc0dBMVVFQXhNa1lqYzVNekkyTm1NdE5tSXhaaTAwWkRCbUxXSTBPRFV0Wm1NMU9UUXhZMlpoTm1ZeApNQjRYRFRJMU1USXpNVEE1TXpZMU0xb1hEVE13TVRJek1EQTVNemcxTTFvd1RqRW5NQ1VHQTFVRUNoTWVaMnRsCk9tNXZaR1Z3YjI5c09tNWhiV1U2WkdWbVlYVnNkQzF3YjI5c01TTXdJUVlEVlFRREV4cHJkV0psYkdWMExXNXYKWkdWd2IyOXNMV0p2YjNSemRISmhjRENDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQgpBTFEzenZUWC8rbldwcjJER29sc3dhcC9WUVBhcWVkZTZrZVRoZ2VzUW11clVqZlVvOURkcWhiZmx0Z2w3T2xUCmRITjZEaitHTlVKZ29paHRidEdxS0VsYUl3ejB4OElyN2lCYWJNbmdwS2xNRWlCMXdvQWhhYm4rcUxuQVczem8KVGhFQWJxOExONm5QUkl6N3FOYWpNWHFvb2x2bytYZ1lNZ0hMM0pwSkxrL1JKSlJOK1BFanduZ2lBM3lUcWtTbwpVNnFmRXBtRXJLdEIrWUg2VWFlWjdOWENSUzNoOFpqUmE3UXRpYityRFVxVnRoN3BFalRjUnBwRjZTNWd0VFF5Cno3bThnZUhBc1JXZlBnWE1kQkgyeldCTmFFMTMvMjdrZnJZSUhRTWk1aDYydzJQR3kyRFgvSUE4TlJDNmtHT0IKcEhKck5FK2Y0NXVrR3Vzby8vcnpsRjhDQXdFQUFhTldNRlF3RGdZRFZSMFBBUUgvQkFRREFnV2dNQk1HQTFVZApKUVFNTUFvR0NDc0dBUVVGQndNQ01Bd0dBMVVkRXdFQi93UUNNQUF3SHdZRFZSMGpCQmd3Rm9BVU4wSEIrMXBMCkU2QnVTanJGdFpoZ0tJREszOUV3RFFZSktvWklodmNOQVFFTEJRQURnZ0dCQUJGVGdLTEY3dzY5U2dFNmwyU0gKVzM1TG92T2ROb3BMZEpJRHFlT201RVkwY0t1Zk43OVpqUyt4TVN1cFZqOE5ZbVJTSzVxcUJmb0Z2b3NhcmYrbApxeVlwNVQvanEyZklCdEhlMFp2OFhQZzFFZWRXcEhJRHFFT1JteUZnOTRncXJ6UndMUU1Wdi9MSFcvV25tVGVICkxHbGRWeURXMkk2SUgzSUNXalR0TFJGK0ViRU1ZK2ZxQXkyOU1QNDUvS095aWFMNWtNUUR3Vkp4cGg1SlczTlQKTi9qeXE0YmZsSEpFWXRvQVdibnpoTnVkcXFmaTdacm43OUl1aHRvL3VPdi8xbGV5MzdPM01aZkk4QWQydnk3WAp0Wlp1eDhDRlNEYnprVE9LTVQ1YWxtZmw0QVVjM3NaZlV6Ui95T0FTL0NPNm5xbW5HRStHQWZybG5pRUhpV044CjhOVTB1OUx1UGc1bVBmY1BFRlpPcmphUFhFdXcvcmhSN1daeHhIM1A4QzNXcFprZWg0dEhLMzloTE5RVVp6US8KZTU5K0xUNEgrR1NidTFUN2tXZVRmeTBIWGlwVE5IZFhydzVaYzJkVEM3RVpzdnh5ZXFsMUtNUE9LaXBxWjlzSQplb21Pc3FXTWtWY1lnN2o1WGZnZGp3WlJGdDY2d0hBVTlCNGdzY3BqQzUrK1hRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\nTPM_BOOTSTRAP_KEY: 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\nVOLUME_PLUGIN_DIR: /home/kubernetes/flexvolume\nZONE: us-west1-b\n"
    kube-labels                = "cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=4,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-memory-gb-scaling-level=16,cloud.google.com/gke-netd-ready=true,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2,cloud.google.com/private-node=false,iam.gke.io/gke-metadata-server-enabled=true"
    kubeconfig                 = "apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    server: https://10.138.0.4\n    certificate-authority: '/etc/srv/kubernetes/pki/ca-certificates.crt'\n  name: default-cluster\ncontexts:\n- context:\n    cluster: default-cluster\n    namespace: default\n    user: exec-plugin-auth\n  name: default-context\ncurrent-context: default-context\nusers:\n- name: exec-plugin-auth\n  user:\n    exec:\n      apiVersion: \"client.authentication.k8s.io/v1beta1\"\n      command: '/home/kubernetes/bin/gke-exec-auth-plugin'\n      args: [\"--cache-dir\", '/var/lib/kubelet/pki/', \"--request-extra-groups\"]\n"
    kubelet-config             = "apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    enabled: true\n  x509:\n    clientCAFile: /etc/srv/kubernetes/pki/ca-certificates.crt\nauthorization:\n  mode: Webhook\ncgroupRoot: /\nclusterDNS:\n- 34.118.224.10\nclusterDomain: cluster.local\nenableDebuggingHandlers: true\nevictionHard:\n  memory.available: 100Mi\n  nodefs.available: 10%\n  nodefs.inodesFree: 5%\n  pid.available: 10%\nfeatureGates:\n  ExecProbeTimeout: false\n  RotateKubeletServerCertificate: true\nkernelMemcgNotification: true\nkind: KubeletConfiguration\nkubeReserved:\n  cpu: 80m\n  ephemeral-storage: 41Gi\n  memory: 2623Mi\nmaxParallelImagePulls: 2\nreadOnlyPort: 0\nserializeImagePulls: false\nserverTLSBootstrap: true\nstaticPodPath: /etc/kubernetes/manifests\n"
    serial-port-logging-enable = "true"
    user-data                  = "#cloud-config\n\nusers:\n  - name: kube-bootstrap-logs-forwarder\n    gecos: User the kube-bootstrap-logs-forwarder.service runs as.\n    system: true\n    shell: /sbin/nologin\n\nwrite_files:\n  - path: /etc/systemd/system/kube-bootstrap-logs-forwarder.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Forwards Kubernetes bootstrap logs to serial port.\n      Before=setup-kubernetes-dir.service\n\n      [Service]\n      User=kube-bootstrap-logs-forwarder\n      Group=systemd-journal\n      SupplementaryGroups=serial\n      ExecStart=journalctl --no-tail --no-pager --follow --utc --output short-iso --unit setup-kubernetes-dir --unit placeholders-presuspend-setup --unit kube-node-installation --unit kube-node-configuration --unit kubelet\n      StandardOutput=tty\n      TTYPath=/dev/ttyS2\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/setup-kubernetes-dir.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Sets up required directories and mounts.\n      After=network-online.target\n\n      [Service]\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecStart=/bin/mkdir -p /home/kubernetes/bin\n      ExecStart=/bin/mount --bind /home/kubernetes/bin /home/kubernetes/bin\n      ExecStart=/bin/mount -o remount,exec /home/kubernetes/bin\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/placeholders-presuspend-setup.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Perform required presuspend logic for Placeholders VM, skip for Non-Placeholders VMs.\n      After=setup-kubernetes-dir.service\n\n      [Service]\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecCondition=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H \"X-Google-Metadata-Request: True\" -o /home/kubernetes/bin/placeholders-presuspend.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/placeholders-presuspend-sh\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/placeholders-presuspend.sh\n      ExecStart=/home/kubernetes/bin/placeholders-presuspend.sh\n\n      [Install]\n      WantedBy=kubernetes.target\n\n\n  - path: /etc/systemd/system/kube-node-installation.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Download and install k8s binaries and configurations\n      After=placeholders-presuspend-setup.service\n\n      [Service]\n      Environment=KUBERNETES_MASTER=false\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecStartPre=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H \"X-Google-Metadata-Request: True\" -o /home/kubernetes/bin/configure.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/configure-sh\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure.sh\n      ExecStart=/home/kubernetes/bin/configure.sh\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/gke-node-reg-checker.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Check node registration with API server\n      After=kube-node-installation.service\n\n      [Service]\n      Type=simple\n      ExecStart=/home/kubernetes/bin/node-registration-checker.sh\n      StandardOutput=journal+console\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/node-registration-checker.sh\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-node-configuration.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Configure kubernetes node\n      After=kube-node-installation.service\n\n      [Service]\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure-helper.sh\n      ExecStart=/home/kubernetes/bin/configure-helper.sh\n      ExecStartPost=systemctl stop kube-bootstrap-logs-forwarder.service\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-logrotate.timer\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Hourly kube-logrotate invocation\n\n      [Timer]\n      OnCalendar=hourly\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-logrotate.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes log rotation\n      After=kube-node-configuration.service\n\n      [Service]\n      Type=oneshot\n      # The relative path is being used as the path is different between image types - for example between Ubuntu and COS. See ExecSearchPath for allowed paths.\n      ExecSearchPath=/usr/bin:/usr/sbin\n      ExecStart=logrotate /etc/logrotate.conf\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kubernetes.target\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes\n\n      [Install]\n      WantedBy=multi-user.target\n\n  - path: /etc/modprobe.d/sunrpc.conf\n    permissions: '0644'\n    owner: root\n    # The GKE metadata server uses ports 987-989, so the sunrpc range should be restricted to be below.\n    content: |\n      options sunrpc max_resvport=986\n\nruncmd:\n  - systemctl enable\n      kube-bootstrap-logs-forwarder.service\n      setup-kubernetes-dir.service\n      placeholders-presuspend-setup.service\n      kube-node-installation.service\n      gke-node-reg-checker.service\n      kube-node-configuration.service\n      kube-logrotate.timer\n      kube-logrotate.service\n      kubernetes.target\n  - systemctl start kubernetes.target\n"
  }

  name = "gke-cluster2-default-pool-8b8d378a-v4wd"

  network_interface {
    access_config {
      nat_ip       = "136.117.86.196"
      network_tier = "PREMIUM"
    }

    alias_ip_range {
      ip_cidr_range         = "10.24.0.0/24"
      subnetwork_range_name = "gke-cluster2-pods-399a6ad9"
    }

    network            = "https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-2e74891f7230/global/networks/default"
    network_ip         = "10.138.0.6"
    stack_type         = "IPV4_ONLY"
    subnetwork         = "https://www.googleapis.com/compute/v1/projects/qwiklabs-gcp-01-2e74891f7230/regions/us-west1/subnetworks/default"
    subnetwork_project = "qwiklabs-gcp-01-2e74891f7230"
  }

  network_performance_config {
    total_egress_bandwidth_tier = "DEFAULT"
  }

  project = "qwiklabs-gcp-01-2e74891f7230"

  scheduling {
    automatic_restart   = true
    on_host_maintenance = "MIGRATE"
    provisioning_model  = "STANDARD"
  }

  service_account {
    email  = "268855880648-compute@developer.gserviceaccount.com"
    scopes = ["https://www.googleapis.com/auth/devstorage.read_only", "https://www.googleapis.com/auth/logging.write", "https://www.googleapis.com/auth/monitoring", "https://www.googleapis.com/auth/service.management.readonly", "https://www.googleapis.com/auth/servicecontrol", "https://www.googleapis.com/auth/trace.append"]
  }

  shielded_instance_config {
    enable_integrity_monitoring = true
    enable_vtpm                 = true
  }

  tags = ["gke-cluster2-399a6ad9-node"]
  zone = "us-west1-b"
}
# terraform import google_compute_instance.gke_cluster2_default_pool_8b8d378a_v4wd projects/qwiklabs-gcp-01-2e74891f7230/zones/us-west1-b/instances/gke-cluster2-default-pool-8b8d378a-v4wd
